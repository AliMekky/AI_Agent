from langchain_groq import ChatGroq
from langchain_community.tools.tavily_search import TavilySearchResults

from langgraph.prebuilt import create_react_agent

from langchain_core.messages.ai import AIMessage
## this AIMessage, it recognizes which message are written by AI and which messages are written by human

from app.config.settings import settings

def get_response_from_ai_agents(llm_id, query, allow_search, system_prompt):
    """
    Generates a response from an AI agent using a specified large language model,
    optional web search tools, and a system-level prompt to control agent behavior.

    This function creates a ReAct-style AI agent powered by a Groq-hosted language
    model. Depending on the value of `allow_search`, the agent may be equipped with
    an online search tool to retrieve up-to-date information. The agent processes
    the provided user query as part of its conversation state, applies the given
    system prompt to guide its reasoning and behavior, and returns the most recent
    AI-generated response.

    Parameters
    ----------
    llm_id : str
        Identifier of the language model to be used (e.g., a LLaMA model hosted on Groq).
    query : list
        The conversation history or current user message(s), represented as a list
        of message objects that the agent will reason over.
    allow_search : bool
        Flag indicating whether the agent is allowed to use web search tools to fetch
        real-time or external information.
    system_prompt : str
        A system-level prompt that defines the role, tone, and behavior of the AI agent.

    Returns
    -------
    str
        The latest response generated by the AI agent. If no AI-generated message
        is found, a fallback message is returned instead.

    Notes
    -----
    The agent follows a ReAct (Reasoning and Acting) pattern, allowing it to reason
    over the conversation state and optionally invoke tools before producing a final
    response. The conversation state maintains message history to support contextual
    and coherent interactions.
    """

    llm = ChatGroq(model = llm_id)

    tools = [TavilySearchResults(max_results=2)] if allow_search else []

    agent = create_react_agent(
        model = llm,
        tools = tools,
        prompt=system_prompt
    )
    # system prompt control the behavior of the agent

    state = {"messages": query}
    # starting the conversation history
    # it means whatever user has said so far so you will keep track of conversation history
    # this will carry a list of all the messages 
    # now we will run the agent with the current conversation state
    
    response = agent.invoke(state)
    # the agent will read all the messages and think the processes

    messages = response.get("messages")

    ai_messages = [message.content for message in messages if isinstance(message, AIMessage)]

    return ai_messages[-1] if ai_messages else "I'm sorry, I couldn't generate a response."






